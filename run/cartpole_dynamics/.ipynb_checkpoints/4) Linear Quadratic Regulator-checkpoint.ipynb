{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1ea257",
   "metadata": {},
   "source": [
    "# Linear Quadratic Regulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539b21d",
   "metadata": {},
   "source": [
    "The previous section showed that the eigenvalues of the stable system regarding the angle and angular velocity of the pole have characteristics of continuous systems rather than discrete systems.\n",
    "\n",
    "Regardless, we build linear quadratic regulators by solving both the continuous and discrete algebraic Ricatti equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4113405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3186bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Matrix\n",
      "[[ 1.0000035e+00 -1.2942681e-05 -2.3801964e-05  1.6305943e-03]\n",
      " [ 2.0008639e-02  9.9992085e-01 -2.6311722e-05 -9.5092575e-04]\n",
      " [-8.2056704e-07 -1.3424688e-02  1.0000260e+00  3.1254122e-01]\n",
      " [-4.4493249e-06 -5.0352475e-05  2.0024499e-02  9.9951327e-01]]\n",
      "B Matrix\n",
      "[[ 6.6651064e-06]\n",
      " [ 1.9508155e-01]\n",
      " [-1.1186228e-05]\n",
      " [-2.9142728e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 00:44:04.751746: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    './cartpole_system_model', custom_objects=None, compile=True, options=None\n",
    ")\n",
    "np_weights = model.get_weights()\n",
    "\n",
    "A = np_weights[0]\n",
    "B = np_weights[1].T\n",
    "print(\"A Matrix\")\n",
    "print(A)\n",
    "print(\"B Matrix\")\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43aa5943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartpole_simulation(K):\n",
    "    env = gym.make('CartPole-v1')\n",
    "    x = env.reset()\n",
    "    cumul_reward = 0\n",
    "    for _ in range(500):\n",
    "        u = np.matmul(-K, x)\n",
    "        if u < 0:\n",
    "            u = 0\n",
    "        else:\n",
    "            u = 1\n",
    "        x, reward, done, _ = env.step(u)\n",
    "        cumul_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    env.close()\n",
    "    return cumul_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8118ce1",
   "metadata": {},
   "source": [
    "We define a cost function for observation/state spaces $x$ and control inputs $u$.\n",
    "\n",
    "$x^T Qx + u^T Ru$,\n",
    "\n",
    "with $Q$ as the state space weight and $R$ as the control input space weight.\n",
    "\n",
    "Infinite-horizon continuous algebraic Ricatti equation (CARE):\n",
    "\n",
    "$Q - S(t)B R^{-1} B^T S(t) + S(t)A + A^T S(t) = 0$\n",
    "\n",
    "The K gain can be derived as\n",
    "\n",
    "$K = R^{-1} B^T S(t)$, \n",
    "\n",
    "which can be used for the control input $u = -Kx$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82bbfe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution\n",
      "[[ 1.10519999e+17  2.01569998e+14 -5.62671191e+14  1.37481907e+14]\n",
      " [ 2.01569998e+14  3.67714030e+11 -1.02621701e+12  2.50800322e+11]\n",
      " [-5.62671191e+14 -1.02621701e+12  2.86462969e+12 -6.99936869e+11]\n",
      " [ 1.37481907e+14  2.50800322e+11 -6.99936869e+11  1.71059032e+11]] \n",
      "\n",
      "Eigenvalues\n",
      "[-3.08798405+0.j         -1.00275954+0.01339002j -1.00275954-0.01339002j\n",
      " -0.99619599+0.j        ] \n",
      "\n",
      "K (Gain)\n",
      "[[-4.69942858e+08 -8.70061097e+05  2.39227217e+06 -5.93293568e+05]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Q = np.diag([1, 1, 10, 100])\n",
    "\n",
    "# R (control input gain) is set as the identity matrix\n",
    "S, Lambda_S, K_gain = control.care(A, B, Q, R=None)\n",
    "\n",
    "print(\"Solution\")\n",
    "print(S, \"\\n\")\n",
    "\n",
    "print(\"Eigenvalues\")\n",
    "print(Lambda_S, \"\\n\")\n",
    "\n",
    "print(\"K (Gain)\")\n",
    "print(K_gain, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d34b496f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cartpole_simulation(K_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c86ad",
   "metadata": {},
   "source": [
    "Infinite-horizon discrete algebraic Ricatti equation (DARE):\n",
    "$S = Q + A^T SA - (A^T S B) {(R + B^T S B)}^-1 (B^T SA)$, \n",
    "\n",
    "where the K gain is,\n",
    "\n",
    "$K = {(R + B^T SB)}^{-1} B^T S A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f422c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution\n",
      "[[ 1.25364207e+05  2.75759689e+03 -2.43295843e+02  1.97238912e+03]\n",
      " [ 2.75759689e+03  2.85394942e+02  1.65239983e+01  1.99380007e+02]\n",
      " [-2.43295843e+02  1.65239983e+01  1.18872284e+02  4.90372483e+01]\n",
      " [ 1.97238912e+03  1.99380007e+02  4.90372483e+01  2.63603442e+02]] \n",
      "\n",
      "Eigenvalues\n",
      "[0.09526306+0.j 0.90502869+0.j 0.99519253+0.j 0.9997579 +0.j] \n",
      "\n",
      "K (Gain)\n",
      "[[-3.1145489  -0.19519992 -1.02162026 -3.57657182]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Q = np.diag([1, 1, 10, 100])\n",
    "\n",
    "# R (control input gain) is set as the identity matrix\n",
    "S, Lambda_S, K_gain = control.dare(A, B, Q, R=None)\n",
    "\n",
    "print(\"Solution\")\n",
    "print(S, \"\\n\")\n",
    "\n",
    "print(\"Eigenvalues\")\n",
    "print(Lambda_S, \"\\n\")\n",
    "\n",
    "print(\"K (Gain)\")\n",
    "print(K_gain, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e622def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cartpole_simulation(K_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0283ef0d",
   "metadata": {},
   "source": [
    "It seems that despite the aforementioned indication of a continuous control system, DARE performs much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17eee49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': array([[-3.1145489 , -0.19519992, -1.02162026, -3.57657182]]), 'S': array([[ 1.25364207e+05,  2.75759689e+03, -2.43295843e+02,\n",
      "         1.97238912e+03],\n",
      "       [ 2.75759689e+03,  2.85394942e+02,  1.65239983e+01,\n",
      "         1.99380007e+02],\n",
      "       [-2.43295843e+02,  1.65239983e+01,  1.18872284e+02,\n",
      "         4.90372483e+01],\n",
      "       [ 1.97238912e+03,  1.99380007e+02,  4.90372483e+01,\n",
      "         2.63603442e+02]]), 'A': array([[ 1.0000035e+00, -1.2942681e-05, -2.3801964e-05,  1.6305943e-03],\n",
      "       [ 2.0008639e-02,  9.9992085e-01, -2.6311722e-05, -9.5092575e-04],\n",
      "       [-8.2056704e-07, -1.3424688e-02,  1.0000260e+00,  3.1254122e-01],\n",
      "       [-4.4493249e-06, -5.0352475e-05,  2.0024499e-02,  9.9951327e-01]],\n",
      "      dtype=float32), 'B': array([[ 6.6651064e-06],\n",
      "       [ 1.9508155e-01],\n",
      "       [-1.1186228e-05],\n",
      "       [-2.9142728e-01]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "save_dare_controller_dict = {\"K\": K_gain, \"S\": S, \"A\": A, \"B\": B}\n",
    "print(save_dare_controller_dict)\n",
    "with open('./cartpole_system_model/dare_controller.pkl', 'wb') as filepath:\n",
    "    pickle.dump(save_dare_controller_dict, filepath, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7468b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
